{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1820,
     "status": "ok",
     "timestamp": 1596727900247,
     "user": {
      "displayName": "CompSci",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHkPlM0Kk1x8Dq9cqiGp99eIZJWIpA10mWUw8HqA=s64",
      "userId": "03806519824403002203"
     },
     "user_tz": -120
    },
    "id": "Yj852dUbyTlR"
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import joblib\n",
    "import numpy as np\n",
    "from quadratic_weighted_kappa import quadratic_weighted_kappa\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5625,
     "status": "ok",
     "timestamp": 1596727952650,
     "user": {
      "displayName": "CompSci",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHkPlM0Kk1x8Dq9cqiGp99eIZJWIpA10mWUw8HqA=s64",
      "userId": "03806519824403002203"
     },
     "user_tz": -120
    },
    "id": "-wa6i3FayU3M"
   },
   "outputs": [],
   "source": [
    "x = joblib.load('essay_ease10_sbert768_simbow_langerr_780_normalized_asap1')\n",
    "x_gib = joblib.load('essay_asap1_780_with200gibberish')\n",
    "y = joblib.load(\"score_asap1\")\n",
    "y_gib = joblib.load('score_asap1_with200gibberish')\n",
    "gib = joblib.load('gibberish_200text_780')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gib = x_gib[:1883]\n",
    "y_gib = y_gib[:1883]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1783, 780)\n",
      "(1883, 780)\n",
      "(200, 780)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x_gib.shape)\n",
    "print(gib.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_extended():\n",
    "    ease_feats = ['Answer Length', 'Word Counts', 'Average Word Length', 'Good n-gram', 'Prompt Overlap',\n",
    "              'Prompt Overlap (synonyms)', 'Punctuation Counts', 'Spelling Error', 'Unique Words', 'Prompt Similarity SBert']\n",
    "\n",
    "    sbert_feats = []\n",
    "    sbert_dim = 768\n",
    "\n",
    "    for i in range(0, sbert_dim):\n",
    "    \tfname = \"sbert_\" + str(i) \n",
    "    \tsbert_feats.append(fname)\n",
    "    \n",
    "    prompt_similarity_bow = [\"Prompt Similarity BOW\"]\n",
    "    lang_error = [\"Language Error\"]\n",
    "    \n",
    "    feature_names = ease_feats + prompt_similarity_bow + lang_error + sbert_feats \n",
    "\n",
    "    print(\"len feature names: \", len(feature_names))\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len feature names:  780\n"
     ]
    }
   ],
   "source": [
    "feature_names = get_feature_names_extended()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 780)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(2000)\n",
    "X_train, X_test, Y_train, Y_test, idx1, idx2 = train_test_split(x_gib, y_gib, indices, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgboost.DMatrix(X_train, label=Y_train, feature_names=feature_names)\n",
    "d_test = xgboost.DMatrix(X_test, label=Y_test, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-rmse:2.13962\n",
      "Will train until test-rmse hasn't improved in 20 rounds.\n",
      "[1]\ttest-rmse:2.03985\n",
      "[2]\ttest-rmse:1.94737\n",
      "[3]\ttest-rmse:1.85841\n",
      "[4]\ttest-rmse:1.77496\n",
      "[5]\ttest-rmse:1.69600\n",
      "[6]\ttest-rmse:1.62066\n",
      "[7]\ttest-rmse:1.54949\n",
      "[8]\ttest-rmse:1.48256\n",
      "[9]\ttest-rmse:1.41866\n",
      "[10]\ttest-rmse:1.35860\n",
      "[11]\ttest-rmse:1.30172\n",
      "[12]\ttest-rmse:1.24795\n",
      "[13]\ttest-rmse:1.19829\n",
      "[14]\ttest-rmse:1.15120\n",
      "[15]\ttest-rmse:1.10686\n",
      "[16]\ttest-rmse:1.06420\n",
      "[17]\ttest-rmse:1.02468\n",
      "[18]\ttest-rmse:0.98770\n",
      "[19]\ttest-rmse:0.95350\n",
      "[20]\ttest-rmse:0.92035\n",
      "[21]\ttest-rmse:0.88962\n",
      "[22]\ttest-rmse:0.86178\n",
      "[23]\ttest-rmse:0.83444\n",
      "[24]\ttest-rmse:0.80985\n",
      "[25]\ttest-rmse:0.78634\n",
      "[26]\ttest-rmse:0.76407\n",
      "[27]\ttest-rmse:0.74371\n",
      "[28]\ttest-rmse:0.72492\n",
      "[29]\ttest-rmse:0.70738\n",
      "[30]\ttest-rmse:0.69159\n",
      "[31]\ttest-rmse:0.67605\n",
      "[32]\ttest-rmse:0.66101\n",
      "[33]\ttest-rmse:0.64775\n",
      "[34]\ttest-rmse:0.63582\n",
      "[35]\ttest-rmse:0.62449\n",
      "[36]\ttest-rmse:0.61338\n",
      "[37]\ttest-rmse:0.60433\n",
      "[38]\ttest-rmse:0.59550\n",
      "[39]\ttest-rmse:0.58647\n",
      "[40]\ttest-rmse:0.57874\n",
      "[41]\ttest-rmse:0.57238\n",
      "[42]\ttest-rmse:0.56628\n",
      "[43]\ttest-rmse:0.56005\n",
      "[44]\ttest-rmse:0.55378\n",
      "[45]\ttest-rmse:0.54831\n",
      "[46]\ttest-rmse:0.54386\n",
      "[47]\ttest-rmse:0.53940\n",
      "[48]\ttest-rmse:0.53501\n",
      "[49]\ttest-rmse:0.53157\n",
      "[50]\ttest-rmse:0.52843\n",
      "[51]\ttest-rmse:0.52551\n",
      "[52]\ttest-rmse:0.52284\n",
      "[53]\ttest-rmse:0.51960\n",
      "[54]\ttest-rmse:0.51718\n",
      "[55]\ttest-rmse:0.51459\n",
      "[56]\ttest-rmse:0.51204\n",
      "[57]\ttest-rmse:0.50983\n",
      "[58]\ttest-rmse:0.50787\n",
      "[59]\ttest-rmse:0.50574\n",
      "[60]\ttest-rmse:0.50449\n",
      "[61]\ttest-rmse:0.50288\n",
      "[62]\ttest-rmse:0.50175\n",
      "[63]\ttest-rmse:0.49995\n",
      "[64]\ttest-rmse:0.49861\n",
      "[65]\ttest-rmse:0.49721\n",
      "[66]\ttest-rmse:0.49602\n",
      "[67]\ttest-rmse:0.49485\n",
      "[68]\ttest-rmse:0.49308\n",
      "[69]\ttest-rmse:0.49191\n",
      "[70]\ttest-rmse:0.49120\n",
      "[71]\ttest-rmse:0.49031\n",
      "[72]\ttest-rmse:0.48978\n",
      "[73]\ttest-rmse:0.48898\n",
      "[74]\ttest-rmse:0.48856\n",
      "[75]\ttest-rmse:0.48836\n",
      "[76]\ttest-rmse:0.48812\n",
      "[77]\ttest-rmse:0.48789\n",
      "[78]\ttest-rmse:0.48781\n",
      "[79]\ttest-rmse:0.48727\n",
      "[80]\ttest-rmse:0.48678\n",
      "[81]\ttest-rmse:0.48635\n",
      "[82]\ttest-rmse:0.48614\n",
      "[83]\ttest-rmse:0.48565\n",
      "[84]\ttest-rmse:0.48499\n",
      "[85]\ttest-rmse:0.48472\n",
      "[86]\ttest-rmse:0.48411\n",
      "[87]\ttest-rmse:0.48392\n",
      "[88]\ttest-rmse:0.48364\n",
      "[89]\ttest-rmse:0.48304\n",
      "[90]\ttest-rmse:0.48262\n",
      "[91]\ttest-rmse:0.48207\n",
      "[92]\ttest-rmse:0.48193\n",
      "[93]\ttest-rmse:0.48110\n",
      "[94]\ttest-rmse:0.48043\n",
      "[95]\ttest-rmse:0.48025\n",
      "[96]\ttest-rmse:0.48017\n",
      "[97]\ttest-rmse:0.47988\n",
      "[98]\ttest-rmse:0.47966\n",
      "[99]\ttest-rmse:0.47915\n",
      "[100]\ttest-rmse:0.47896\n",
      "[101]\ttest-rmse:0.47876\n",
      "[102]\ttest-rmse:0.47853\n",
      "[103]\ttest-rmse:0.47874\n",
      "[104]\ttest-rmse:0.47874\n",
      "[105]\ttest-rmse:0.47852\n",
      "[106]\ttest-rmse:0.47858\n",
      "[107]\ttest-rmse:0.47857\n",
      "[108]\ttest-rmse:0.47809\n",
      "[109]\ttest-rmse:0.47798\n",
      "[110]\ttest-rmse:0.47803\n",
      "[111]\ttest-rmse:0.47762\n",
      "[112]\ttest-rmse:0.47723\n",
      "[113]\ttest-rmse:0.47695\n",
      "[114]\ttest-rmse:0.47700\n",
      "[115]\ttest-rmse:0.47707\n",
      "[116]\ttest-rmse:0.47696\n",
      "[117]\ttest-rmse:0.47679\n",
      "[118]\ttest-rmse:0.47663\n",
      "[119]\ttest-rmse:0.47641\n",
      "[120]\ttest-rmse:0.47608\n",
      "[121]\ttest-rmse:0.47615\n",
      "[122]\ttest-rmse:0.47584\n",
      "[123]\ttest-rmse:0.47571\n",
      "[124]\ttest-rmse:0.47565\n",
      "[125]\ttest-rmse:0.47565\n",
      "[126]\ttest-rmse:0.47560\n",
      "[127]\ttest-rmse:0.47552\n",
      "[128]\ttest-rmse:0.47540\n",
      "[129]\ttest-rmse:0.47521\n",
      "[130]\ttest-rmse:0.47522\n",
      "[131]\ttest-rmse:0.47494\n",
      "[132]\ttest-rmse:0.47500\n",
      "[133]\ttest-rmse:0.47517\n",
      "[134]\ttest-rmse:0.47491\n",
      "[135]\ttest-rmse:0.47485\n",
      "[136]\ttest-rmse:0.47474\n",
      "[137]\ttest-rmse:0.47480\n",
      "[138]\ttest-rmse:0.47496\n",
      "[139]\ttest-rmse:0.47504\n",
      "[140]\ttest-rmse:0.47474\n",
      "[141]\ttest-rmse:0.47494\n",
      "[142]\ttest-rmse:0.47507\n",
      "[143]\ttest-rmse:0.47491\n",
      "[144]\ttest-rmse:0.47482\n",
      "[145]\ttest-rmse:0.47484\n",
      "[146]\ttest-rmse:0.47501\n",
      "[147]\ttest-rmse:0.47492\n",
      "[148]\ttest-rmse:0.47459\n",
      "[149]\ttest-rmse:0.47496\n",
      "[150]\ttest-rmse:0.47512\n",
      "[151]\ttest-rmse:0.47497\n",
      "[152]\ttest-rmse:0.47510\n",
      "[153]\ttest-rmse:0.47503\n",
      "[154]\ttest-rmse:0.47497\n",
      "[155]\ttest-rmse:0.47504\n",
      "[156]\ttest-rmse:0.47512\n",
      "[157]\ttest-rmse:0.47493\n",
      "[158]\ttest-rmse:0.47517\n",
      "[159]\ttest-rmse:0.47498\n",
      "[160]\ttest-rmse:0.47506\n",
      "[161]\ttest-rmse:0.47496\n",
      "[162]\ttest-rmse:0.47509\n",
      "[163]\ttest-rmse:0.47482\n",
      "[164]\ttest-rmse:0.47478\n",
      "[165]\ttest-rmse:0.47474\n",
      "[166]\ttest-rmse:0.47477\n",
      "[167]\ttest-rmse:0.47477\n",
      "[168]\ttest-rmse:0.47489\n",
      "Stopping. Best iteration:\n",
      "[148]\ttest-rmse:0.47459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.train({\"learning_rate\": 0.05, \"max_depth\":3}, d_train, 200, evals = [(d_test, \"test\")], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6975\n",
      "qwk:  0.8908181594054873\n"
     ]
    }
   ],
   "source": [
    "yxgb_pred = model.predict(d_test)\n",
    "yxgb_pred = np.round(yxgb_pred)\n",
    "print(\"accuracy: \", accuracy_score(yxgb_pred, Y_test))\n",
    "print(\"qwk: \", quadratic_weighted_kappa(yxgb_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_asap6_extended_780_gibberish_1']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"model_asap6_extended_780_gibberish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model 5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#kf.get_n_splits(x, y)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = xgboost.XGBRegressor(objective ='reg:squarederror',\n",
    "                colsample_bytree=0.4,\n",
    "                 gamma=0,                 \n",
    "                 learning_rate=0.07,\n",
    "                 max_depth=4,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.6,\n",
    "                 seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training using original + gibberish data (1983 essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loop - 1\n",
      "========\n",
      "Qwk :  0.9332221766140263\n",
      "Acc :  0.5145888594164456\n",
      "len all :  377\n",
      "Qwk original :  0.7685594603303295\n",
      "Acc original :  0.4871060171919771\n",
      "len ori :  349\n",
      "Acc gibberish :  0.8571428571428571\n",
      "len gib :  28\n",
      "\n",
      "Loop - 2\n",
      "========\n",
      "Qwk :  0.9234258282062929\n",
      "Acc :  0.5358090185676393\n",
      "len all :  377\n",
      "Qwk original :  0.7790504963314631\n",
      "Acc original :  0.5167597765363129\n",
      "len ori :  358\n",
      "Acc gibberish :  0.8947368421052632\n",
      "len gib :  19\n",
      "\n",
      "Loop - 3\n",
      "========\n",
      "Qwk :  0.9110625482058251\n",
      "Acc :  0.5039787798408488\n",
      "len all :  377\n",
      "Qwk original :  0.7826257833288863\n",
      "Acc original :  0.481994459833795\n",
      "len ori :  361\n",
      "Acc gibberish :  1.0\n",
      "len gib :  16\n",
      "\n",
      "Loop - 4\n",
      "========\n",
      "Qwk :  0.9298745939412254\n",
      "Acc :  0.5478723404255319\n",
      "len all :  376\n",
      "Qwk original :  0.7918463347706781\n",
      "Acc original :  0.5225988700564972\n",
      "len ori :  354\n",
      "Acc gibberish :  0.9545454545454546\n",
      "len gib :  22\n",
      "\n",
      "Loop - 5\n",
      "========\n",
      "Qwk :  0.9043023578029181\n",
      "Acc :  0.4946808510638298\n",
      "len all :  376\n",
      "Qwk original :  0.7620191508299019\n",
      "Acc original :  0.47645429362880887\n",
      "len ori :  361\n",
      "Acc gibberish :  0.9333333333333333\n",
      "len gib :  15\n",
      "\n",
      "Mean QWK :  0.9203775009540575\n",
      "\n",
      "Mean QWK Original :  0.7768202451182518\n",
      "\n",
      "Mean Accuracy :  0.5193859698628591\n",
      "\n",
      "Mean Accuracy Original :  0.4969826834494782\n",
      "\n",
      "Mean Accuracy Gibberish :  0.9279516974253816\n"
     ]
    }
   ],
   "source": [
    "qwk_scores = []\n",
    "qwk_scores_ori = []\n",
    "\n",
    "acc_scores = []\n",
    "acc_scores_ori = []\n",
    "acc_scores_gib = []\n",
    "\n",
    "\n",
    "test_indices = []\n",
    "test_indices_ori = []\n",
    "test_indices_gib = []\n",
    "\n",
    "pred_labels = []\n",
    "pred_labels_ori = []\n",
    "pred_labels_gib = []\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for train_index, test_index in kf.split(x_gib, y_gib):\n",
    "    \n",
    "    print()\n",
    "    print(\"Loop -\", counter)\n",
    "    print(\"========\")\n",
    "    counter = counter + 1\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = x_gib[train_index], x_gib[test_index], y_gib[train_index], y_gib[test_index]\n",
    "         \n",
    "    model2.fit(X_train, Y_train)\n",
    "    \n",
    "    \n",
    "    # PREDICT AND EVALUATE ALL ESSAYS\n",
    "    predict = model2.predict(X_test)\n",
    "    predict = np.round(predict)\n",
    "    \n",
    "    pred_labels.extend(predict)\n",
    "    test_indices.extend(test_index)\n",
    "    \n",
    "    result_qwk = quadratic_weighted_kappa(Y_test, predict)\n",
    "    print(\"Qwk : \", result_qwk)\n",
    "    qwk_scores.append(result_qwk)\n",
    "    \n",
    "    result_acc = accuracy_score(Y_test, predict)\n",
    "    print(\"Acc : \", result_acc)\n",
    "    acc_scores.append(result_acc)\n",
    "    \n",
    "    print(\"len all : \", len(test_index))\n",
    "\n",
    "    # PREDICT AND EVALUATE ONLY ORIGINAL ESSAY\n",
    "    test_index_ori = [a for a in test_index if a < 1783]\n",
    "    x_test_ori = x_gib[test_index_ori]\n",
    "    y_test_ori = y_gib[test_index_ori]\n",
    "    predict_ori = model2.predict(x_test_ori)\n",
    "    predict_ori = np.round(predict_ori)\n",
    "    pred_labels_ori.extend(predict_ori)\n",
    "    \n",
    "    result_qwk_ori = quadratic_weighted_kappa(y_test_ori, predict_ori)\n",
    "    print(\"Qwk original : \", result_qwk_ori)\n",
    "    qwk_scores_ori.append(result_qwk_ori)\n",
    "    \n",
    "    result_acc_ori = accuracy_score(y_test_ori, predict_ori)\n",
    "    print(\"Acc original : \", result_acc_ori)\n",
    "    acc_scores_ori.append(result_acc_ori)\n",
    "    \n",
    "    print(\"len ori : \", len(test_index_ori))\n",
    "    \n",
    "    # PREDICT AND EVALUATE ONLY GIBBERISH ESSAY\n",
    "    test_index_gib = [a for a in test_index if a > 1782]\n",
    "    x_test_gib = x_gib[test_index_gib]\n",
    "    y_test_gib = y_gib[test_index_gib]\n",
    "    predict_gib = model2.predict(x_test_gib)\n",
    "    predict_gib = np.round(predict_gib)\n",
    "    pred_labels_gib.extend(predict_gib)\n",
    "    \n",
    "    result_acc_gib = accuracy_score(y_test_gib, predict_gib)\n",
    "    print(\"Acc gibberish : \", result_acc_gib)\n",
    "    acc_scores_gib.append(result_acc_gib)\n",
    "    \n",
    "    print(\"len gib : \", len(test_index_gib))\n",
    "\n",
    "print(\"\\nMean QWK : \", np.mean(qwk_scores))\n",
    "print(\"\\nMean QWK Original : \", np.mean(qwk_scores_ori))\n",
    "\n",
    "print(\"\\nMean Accuracy : \", np.mean(acc_scores))\n",
    "print(\"\\nMean Accuracy Original : \", np.mean(acc_scores_ori))\n",
    "print(\"\\nMean Accuracy Gibberish : \", np.mean(acc_scores_gib))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training using original data (1783 essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loop - 1\n",
      "========\n",
      "Qwk :  0.8082407525645937\n",
      "Acc :  0.484593837535014\n",
      "len all :  357\n",
      "Acc gibberish :  0.0\n",
      "len gib :  200\n",
      "\n",
      "Loop - 2\n",
      "========\n",
      "Qwk :  0.7596110180240844\n",
      "Acc :  0.4677871148459384\n",
      "len all :  357\n",
      "Acc gibberish :  0.0\n",
      "len gib :  200\n",
      "\n",
      "Loop - 3\n",
      "========\n",
      "Qwk :  0.7823694002942279\n",
      "Acc :  0.48179271708683474\n",
      "len all :  357\n",
      "Acc gibberish :  0.0\n",
      "len gib :  200\n",
      "\n",
      "Loop - 4\n",
      "========\n",
      "Qwk :  0.7724125555173393\n",
      "Acc :  0.5365168539325843\n",
      "len all :  356\n",
      "Acc gibberish :  0.0\n",
      "len gib :  200\n",
      "\n",
      "Loop - 5\n",
      "========\n",
      "Qwk :  0.7906373334375365\n",
      "Acc :  0.4859550561797753\n",
      "len all :  356\n",
      "Acc gibberish :  0.0\n",
      "len gib :  200\n",
      "\n",
      "Mean QWK :  0.7826542119675564\n",
      "\n",
      "Mean Accuracy :  0.4913291159160293\n",
      "\n",
      "Mean Accuracy Gibberish :  0.0\n"
     ]
    }
   ],
   "source": [
    "qwk_scores = []\n",
    "\n",
    "acc_scores = []\n",
    "acc_scores_gib = []\n",
    "\n",
    "test_indices = []\n",
    "test_indices_gib = []\n",
    "\n",
    "pred_labels = []\n",
    "pred_labels_gib = []\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    \n",
    "    print()\n",
    "    print(\"Loop -\", counter)\n",
    "    print(\"========\")\n",
    "    counter = counter + 1\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = x[train_index], x[test_index], y[train_index], y[test_index]\n",
    "         \n",
    "    model2.fit(X_train, Y_train)    \n",
    "    \n",
    "    # PREDICT AND EVALUATE ORIGINAL ESSAYS\n",
    "    predict = model2.predict(X_test)\n",
    "    predict = np.round(predict)\n",
    "    \n",
    "    pred_labels.extend(predict)\n",
    "    test_indices.extend(test_index)\n",
    "    \n",
    "    result_qwk = quadratic_weighted_kappa(Y_test, predict)\n",
    "    print(\"Qwk : \", result_qwk)\n",
    "    qwk_scores.append(result_qwk)\n",
    "    \n",
    "    result_acc = accuracy_score(Y_test, predict)\n",
    "    print(\"Acc : \", result_acc)\n",
    "    acc_scores.append(result_acc)\n",
    "    \n",
    "    print(\"len all : \", len(test_index))\n",
    "    \n",
    "    # PREDICT AND EVALUATE ONLY GIBBERISH ESSAY\n",
    "    x_test_gib = gib\n",
    "    y_test_gib = np.zeros(200)\n",
    "    predict_gib = model2.predict(x_test_gib)\n",
    "    predict_gib = np.round(predict_gib)\n",
    "    pred_labels_gib.extend(predict_gib)\n",
    "    \n",
    "    result_acc_gib = accuracy_score(y_test_gib, predict_gib)\n",
    "    print(\"Acc gibberish : \", result_acc_gib)\n",
    "    acc_scores_gib.append(result_acc_gib)\n",
    "    \n",
    "    print(\"len gib : \", len(x_test_gib))\n",
    "\n",
    "print(\"\\nMean QWK : \", np.mean(qwk_scores))\n",
    "\n",
    "print(\"\\nMean Accuracy : \", np.mean(acc_scores))\n",
    "print(\"\\nMean Accuracy Gibberish : \", np.mean(acc_scores_gib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_labels_gib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4.0: 411,\n",
       "         5.0: 319,\n",
       "         6.0: 91,\n",
       "         3.0: 132,\n",
       "         8.0: 12,\n",
       "         7.0: 25,\n",
       "         9.0: 8,\n",
       "         2.0: 2})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(pred_labels_gib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783\n",
      "1783\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_labels))\n",
    "print(len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dict(zip(test_indices, pred_labels))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = { key: a[key] for key in a.keys() if key > 1799 }\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 96, 1.0: 4})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with 100 gibberish\n",
    "Counter(b.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-0.0: 196, 1.0: 4})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with 200 gibberish\n",
    "Counter(b.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 780)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 100 other gibberish (by 100 training)\n",
    "x_gib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 780)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_gib_100 = x_gib[1900:2000]\n",
    "x_gib_100 = x_gib[1800:1900]\n",
    "x_gib_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gib_100 = xgboost.DMatrix(x_gib_100, feature_names=feature_names)\n",
    "pred_gib_100 = model.predict(d_gib_100)\n",
    "pred_gib_100 = np.round(pred_gib_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-0.0: 98, 1.0: 2})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(pred_gib_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 3.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, -0.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 4.0, 4.0, 4.0, 4.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 1.0, 2.0, 2.0, 4.0, 3.0, 2.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 1.0, 4.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 3.0, 1.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 4.0, 4.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 4.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 4.0, 0.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 4.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 0.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0]\n",
      "[4, 2, 3, 2, 3, 3, 2, 2, 2, 1, 4, 3, 1, 3, 2, 2, 3, 3, 2, 1, 1, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 4, 1, 2, 3, 4, 4, 2, 3, 2, 4, 3, 3, 1, 3, 3, 2, 3, 2, 2, 2, 3, 4, 1, 2, 3, 3, 3, 4, 4, 4, 2, 3, 1, 3, 1, 3, 3, 2, 3, 3, 4, 2, 2, 4, 2, 4, 2, 3, 3, 4, 2, 3, 2, 3, 2, 4, 2, 4, 3, 4, 3, 3, 4, 3, 2, 2, 4, 4, 3, 3, 2, 3, 3, 0, 3, 2, 2, 3, 4, 2, 2, 3, 3, 4, 3, 3, 3, 3, 3, 2, 3, 3, 2, 4, 3, 2, 3, 3, 1, 3, 3, 3, 3, 4, 2, 2, 4, 1, 3, 2, 2, 4, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 3, 2, 3, 4, 1, 2, 2, 4, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2, 3, 2, 1, 3, 2, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 2, 0, 2, 3, 2, 2, 3, 2, 4, 3, 3, 2, 3, 1, 4, 4, 4, 3, 4, 3, 2, 4, 3, 2, 2, 3, 3, 3, 3, 4, 3, 2, 2, 4, 1, 3, 3, 4, 3, 1, 1, 3, 3, 3, 4, 4, 3, 3, 2, 0, 2, 3, 3, 3, 3, 4, 4, 3, 3, 1, 2, 2, 3, 2, 3, 3, 1, 4, 3, 3, 2, 1, 3, 3, 3, 2, 2, 2, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 4, 1, 4, 3, 2, 3, 4, 3, 2, 1, 3, 4, 2, 3, 2, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3, 3, 1, 3, 4, 3, 4, 3, 2, 2, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 3, 2, 2, 3, 2, 4, 1, 3, 2, 3, 3, 2, 3, 3, 4, 2, 3, 4, 2, 3, 2, 1, 3, 3, 4, 2, 3, 3, 3, 3, 2, 3, 2, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 3, 3, 0, 3, 4, 2, 2, 3, 4, 3, 3, 3, 3, 3, 2, 1, 3, 4, 4, 1, 3, 3, 4, 3, 3, 4, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 4, 3, 1, 3, 2, 2, 2, 2, 2, 3, 3, 4, 4, 3, 4, 3, 4, 3, 2, 1, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 2, 2, 3, 1, 3, 3, 4, 3, 2, 4, 3, 3, 3, 1, 3, 2, 4, 3, 3, 2, 3, 2, 4, 1, 2, 3, 3, 2, 3, 3, 3, 4, 2, 4, 1, 3, 4, 1, 3, 4, 3, 3, 2, 4, 1, 4, 3, 2, 4, 3, 2, 4, 2, 3, 3, 2, 3, 3, 3, 3, 3, 4, 3, 3, 4, 2, 4, 3, 3, 1, 3, 3, 2, 3, 3, 3, 4, 2, 3, 3, 3, 4, 2, 3, 2, 2, 2, 3, 4, 4, 4, 3, 4, 2, 2, 3, 2, 3, 3, 3, 2, 1, 1, 4, 3, 4, 4, 3, 3, 3, 2, 3, 2, 2, 3, 1, 4, 3, 1, 3, 3, 2, 3, 4, 3, 3, 3, 4, 3, 3, 1, 2, 3, 3, 4, 3, 3, 2, 3, 3, 4, 2, 3, 4, 2, 2, 3, 3, 2, 4, 3, 1, 3, 4, 3, 3, 4, 3, 3, 3, 1, 3, 2, 1, 2, 3, 4, 1, 4, 4, 3, 3, 3, 2, 3, 3, 3, 2, 4, 1, 3, 3, 3, 3, 2, 3, 3, 4, 3, 3, 2, 3, 3, 2, 2, 4, 3, 2, 3, 3, 1, 2, 3, 3, 3, 3, 0, 2, 1, 3, 3, 3, 2, 2, 3, 3, 4, 2, 2, 2, 3, 3, 1, 3, 2, 4, 2, 3, 2, 2, 4, 2, 3, 3, 4, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 4, 4, 3, 2, 1, 4, 1, 2, 1, 3, 1, 4, 4, 4, 4, 2, 1, 2, 3, 3, 2, 3, 4, 4, 3, 2, 2, 3, 4, 2, 3, 2, 3, 3, 3, 3, 4, 2, 2, 2, 4, 3, 4, 3, 3, 4, 3, 4, 2, 2, 1, 3, 3, 3, 3, 4, 2, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 4, 2, 3, 4, 3, 4, 3, 3, 3, 2, 1, 3, 2, 3, 3, 3, 3, 2, 4, 3, 4, 3, 3, 3, 3, 2, 4, 2, 3, 4, 3, 2, 3, 2, 3, 3, 2, 3, 3, 4, 2, 2, 2, 3, 4, 2, 3, 3, 3, 4, 2, 1, 3, 3, 3, 3, 3, 4, 3, 3, 1, 3, 2, 1, 1, 3, 3, 4, 2, 2, 3, 3, 2, 1, 4, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 2, 1, 3, 3, 2, 2, 3, 2, 2, 1, 1, 3, 3, 2, 2, 3, 2, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 2, 4, 3, 1, 2, 3, 2, 1, 3, 3, 0, 2, 1, 3, 3, 3, 3, 3, 4, 1, 1, 2, 4, 4, 4, 2, 4, 1, 1, 2, 3, 3, 3, 3, 3, 2, 1, 4, 1, 2, 2, 1, 3, 3, 3, 1, 4, 3, 4, 2, 4, 2, 3, 3, 3, 2, 3, 3, 4, 3, 3, 2, 2, 1, 3, 3, 2, 3, 2, 4, 1, 3, 2, 3, 4, 3, 3, 1, 2, 2, 4, 3, 2, 0, 3, 2, 3, 3, 3, 3, 2, 2, 3, 3, 4, 3, 2, 4, 3, 3, 3, 4, 2, 4, 1, 1, 4, 2, 3, 3, 2, 2, 3, 4, 3, 1, 4, 2, 3, 3, 3, 2, 4, 3, 3, 3, 3, 3, 3, 4, 3, 2, 4, 4, 1, 3, 3, 3, 4, 4, 2, 3, 3, 3, 2, 2, 4, 1, 3, 3, 4, 2, 3, 4, 4, 3, 3, 3, 2, 2, 3, 1, 2, 4, 3, 2, 2, 2, 2, 4, 4, 2, 3, 2, 4, 2, 4, 3, 2, 4, 3, 4, 3, 3, 3, 2, 3, 4, 3, 1, 4, 4, 3, 4, 3, 2, 2, 3, 3, 3, 3, 3, 4, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 4, 3, 3, 4, 3, 2, 3, 2, 2, 4, 3, 2, 4, 1, 2, 4, 4, 3, 2, 2, 3, 1, 1, 3, 2, 2, 1, 4, 3, 4, 2, 4, 3, 3, 1, 2, 2, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4, 2, 2, 3, 3, 1, 3, 3, 3, 4, 3, 3, 4, 2, 3, 1, 2, 3, 2, 3, 3, 3, 4, 3, 2, 4, 3, 3, 3, 1, 4, 3, 3, 3, 3, 1, 4, 3, 3, 1, 1, 4, 2, 3, 3, 3, 3, 4, 4, 4, 3, 3, 1, 1, 2, 3, 3, 2, 3, 2, 4, 4, 3, 3, 4, 3, 4, 2, 2, 3, 3, 2, 4, 3, 3, 3, 3, 2, 4, 4, 3, 4, 3, 3, 2, 3, 3, 4, 4, 3, 3, 4, 3, 2, 3, 2, 3, 3, 1, 2, 3, 4, 3, 4, 2, 2, 3, 1, 4, 1, 3, 3, 3, 2, 3, 2, 2, 2, 3, 4, 3, 2, 4, 1, 4, 3, 4, 4, 2, 1, 3, 4, 3, 3, 3, 2, 2, 4, 3, 2, 4, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 4, 2, 2, 3, 3, 2, 2, 2, 3, 2, 4, 3, 2, 3, 3, 3, 2, 2, 1, 1, 4, 3, 4, 2, 3, 3, 4, 4, 4, 3, 2, 3, 2, 4, 1, 3, 3, 3, 3, 3, 1, 3, 3, 1, 2, 1, 3, 3, 1, 4, 3, 2, 2, 3, 3, 2, 2, 3, 3, 2, 3, 3, 1, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 1, 3, 4, 4, 2, 4, 2, 3, 4, 3, 2, 2, 1, 1, 3, 3, 3, 1, 3, 3, 4, 2, 3, 4, 3, 3, 3, 1, 3, 4, 4, 4, 3, 1, 2, 3, 3, 2, 4, 3, 3, 2, 3, 4, 4, 4, 3, 2, 3, 4, 3, 3, 2, 3, 1, 3, 2, 4, 3, 3, 3, 3, 2, 1, 3, 4, 3, 4, 2, 3, 3, 3, 4, 2, 3, 2, 2, 2, 3, 4, 3, 4, 2, 1, 3, 2, 2, 2, 3, 2, 0, 2, 2, 3, 2, 2, 4, 4, 2, 1, 4, 3, 3, 2, 3, 2, 4, 3, 3, 4, 3, 3, 2, 1, 3, 2, 2, 3, 3, 3, 2, 4, 3, 1, 4, 4, 3, 3, 3, 3, 1, 4, 3, 4, 2, 3, 1, 3, 4, 3, 3, 3, 2, 1, 2, 3, 4, 4, 3, 2, 2, 4, 3, 4, 2, 2, 3, 1, 3, 3, 3, 3, 3, 4, 2, 4, 2, 3, 3, 3, 2, 3, 3, 4, 3, 2, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 2, 3, 1, 4, 4, 3, 3, 3, 3, 2, 3, 1, 4, 3, 3, 3, 2, 2, 1, 4, 3, 3, 3, 3, 4, 1, 3, 2, 1, 3, 3, 3, 3, 1, 4, 4, 0, 2, 4, 3, 2, 2, 1, 1, 4, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 4, 3, 3, 3, 1, 3, 2, 3, 3, 3, 4, 1, 3, 2, 2, 2, 3, 1, 3, 2, 2, 2, 2, 3, 1, 3, 4, 3, 4, 3, 3, 4, 4, 2, 3, 3, 3, 4, 2, 3, 1, 3, 3, 2, 4, 3, 4, 3, 2, 3, 3, 3, 1, 1, 2, 3, 2, 2, 4, 3, 3, 3, 1, 1, 3, 2, 4, 3, 4, 3, 3, 3, 2, 4, 3, 2, 2, 3, 3, 3, 1, 2, 2, 3, 1, 3, 2, 4, 2, 2, 1, 1, 2, 3, 3, 3, 4, 2, 3, 2, 2, 4, 2, 3, 3, 3, 3, 3, 3, 2, 3, 4, 4, 2, 1, 1, 4, 2, 4, 3, 1, 1, 1, 3, 3, 2, 4, 3, 3, 2, 3, 2, 4, 0, 4, 3, 3, 3, 4, 3, 2, 1, 2, 3, 1, 3, 4, 3, 2, 3, 3, 4, 1, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "pred_labels_int = list(map(int, pred_labels))\n",
    "print(pred_labels)\n",
    "print(pred_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, -0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 4.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 1.0, 2.0, 3.0, 3.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0]\n",
      "[3, 2, 3, 2, 3, 3, 2, 2, 1, 1, 3, 3, 1, 3, 2, 3, 3, 3, 2, 2, 1, 2, 2, 2, 2, 3, 4, 3, 2, 3, 3, 3, 2, 3, 3, 1, 2, 3, 4, 4, 2, 3, 2, 4, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 4, 1, 2, 3, 3, 3, 4, 4, 4, 2, 3, 1, 3, 2, 3, 3, 2, 3, 3, 4, 3, 2, 4, 2, 3, 2, 3, 3, 4, 2, 3, 2, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 3, 2, 2, 3, 4, 3, 3, 3, 3, 3, 0, 3, 2, 2, 3, 4, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 4, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 4, 1, 2, 2, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 4, 3, 2, 3, 3, 3, 4, 1, 2, 3, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 3, 3, 3, 4, 2, 3, 3, 3, 3, 2, 2, 0, 2, 3, 3, 2, 3, 2, 4, 3, 3, 2, 3, 1, 4, 3, 3, 3, 4, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 4, 3, 2, 2, 4, 1, 4, 2, 4, 3, 2, 1, 2, 3, 3, 4, 3, 3, 3, 2, 0, 3, 3, 3, 2, 3, 4, 3, 3, 3, 1, 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 1, 3, 3, 3, 2, 2, 2, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 4, 1, 4, 3, 2, 3, 3, 3, 1, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 2, 4, 3, 2, 3, 4, 3, 3, 3, 3, 3, 4, 3, 2, 1, 3, 2, 4, 1, 3, 2, 3, 3, 2, 3, 2, 4, 2, 3, 4, 2, 3, 2, 1, 3, 3, 4, 2, 4, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 1, 3, 4, 1, 2, 3, 3, 3, 3, 3, 2, 4, 2, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 4, 3, 2, 3, 2, 4, 3, 3, 1, 3, 3, 3, 3, 3, 2, 2, 3, 3, 0, 3, 2, 2, 2, 2, 2, 3, 3, 4, 4, 3, 3, 3, 4, 3, 2, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 3, 2, 3, 3, 4, 3, 2, 3, 2, 3, 3, 2, 3, 2, 4, 3, 2, 2, 3, 2, 4, 1, 2, 3, 3, 2, 2, 3, 3, 4, 2, 4, 1, 2, 3, 1, 3, 4, 3, 4, 2, 4, 1, 4, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 4, 3, 2, 4, 3, 2, 3, 2, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 1, 2, 2, 3, 4, 4, 3, 3, 3, 2, 2, 2, 2, 3, 3, 3, 2, 2, 1, 4, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 3, 1, 3, 2, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 4, 3, 3, 2, 3, 3, 4, 2, 3, 4, 2, 2, 3, 3, 2, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 1, 3, 2, 1, 2, 3, 4, 1, 4, 4, 3, 3, 3, 2, 3, 3, 3, 2, 4, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 2, 2, 3, 3, 3, 1, 2, 1, 3, 2, 3, 2, 2, 3, 3, 4, 2, 1, 2, 3, 3, 0, 3, 2, 3, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 1, 1, 4, 1, 2, 1, 3, 1, 3, 3, 3, 3, 2, 1, 3, 2, 2, 2, 3, 4, 4, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 4, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 1, 1, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 2, 4, 2, 3, 4, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 2, 2, 4, 4, 3, 3, 3, 3, 4, 2, 1, 3, 3, 3, 3, 3, 4, 3, 2, 2, 3, 1, 2, 0, 3, 3, 4, 2, 2, 3, 3, 2, 1, 3, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 1, 3, 3, 2, 2, 3, 2, 1, 2, 2, 3, 3, 2, 2, 3, 2, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 2, 3, 3, 1, 2, 3, 2, 1, 3, 3, 1, 2, 1, 3, 3, 3, 2, 3, 4, 1, 1, 2, 3, 3, 3, 2, 4, 2, 1, 2, 3, 3, 3, 3, 3, 3, 1, 4, 2, 3, 2, 1, 3, 3, 2, 1, 4, 3, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 1, 3, 3, 2, 3, 2, 4, 1, 3, 1, 3, 3, 2, 3, 2, 3, 1, 3, 4, 2, 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3, 4, 3, 2, 3, 3, 3, 3, 3, 2, 4, 1, 2, 4, 2, 2, 3, 2, 2, 3, 4, 3, 1, 3, 2, 3, 3, 2, 2, 4, 3, 3, 3, 3, 3, 4, 3, 2, 2, 3, 3, 1, 3, 3, 3, 3, 4, 2, 3, 3, 3, 2, 2, 4, 2, 3, 3, 4, 2, 3, 4, 4, 3, 3, 3, 3, 2, 3, 1, 2, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 1, 3, 4, 3, 4, 3, 2, 2, 3, 3, 3, 3, 3, 4, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 4, 3, 3, 4, 3, 2, 3, 3, 2, 3, 3, 2, 4, 1, 2, 3, 4, 3, 2, 2, 2, 1, 1, 3, 2, 2, 1, 4, 3, 3, 2, 3, 3, 3, 1, 1, 2, 3, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 4, 2, 2, 1, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 2, 3, 3, 2, 1, 4, 3, 3, 2, 2, 4, 2, 3, 3, 3, 3, 4, 3, 4, 3, 3, 1, 1, 2, 3, 3, 2, 3, 1, 3, 4, 3, 3, 3, 3, 3, 2, 2, 4, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 1, 2, 3, 4, 2, 4, 2, 2, 3, 1, 3, 1, 2, 3, 2, 2, 3, 2, 2, 2, 3, 4, 3, 2, 3, 1, 3, 2, 3, 4, 2, 1, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 2, 2, 1, 1, 3, 2, 4, 2, 3, 3, 4, 3, 4, 3, 2, 3, 2, 4, 1, 2, 3, 2, 3, 3, 1, 3, 3, 1, 2, 1, 3, 3, 2, 4, 3, 2, 2, 3, 3, 1, 2, 2, 4, 2, 3, 3, 1, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 1, 3, 3, 3, 2, 4, 3, 2, 3, 3, 2, 2, 1, 3, 4, 4, 2, 4, 2, 3, 4, 3, 2, 2, 1, 1, 3, 3, 3, 1, 4, 3, 3, 3, 3, 3, 3, 3, 2, 1, 3, 4, 4, 3, 3, 1, 2, 4, 2, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 2, 3, 2, 4, 3, 3, 3, 3, 2, 1, 3, 4, 3, 4, 2, 3, 3, 3, 4, 2, 3, 2, 2, 2, 2, 3, 3, 4, 3, 1, 3, 2, 2, 1, 3, 2, 1, 2, 1, 3, 2, 2, 4, 3, 2, 1, 4, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 1, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 4, 4, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 2, 3, 3, 3, 4, 2, 1, 2, 2, 3, 4, 3, 3, 2, 4, 3, 3, 2, 2, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 2, 3, 2, 3, 2, 4, 3, 2, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 2, 3, 1, 3, 4, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 4, 2, 2, 1, 3, 3, 3, 3, 2, 3, 2, 3, 2, 1, 3, 3, 3, 3, 1, 3, 3, 0, 2, 3, 3, 2, 3, 1, 1, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 2, 4, 3, 2, 3, 1, 3, 2, 3, 3, 3, 3, 1, 3, 2, 2, 2, 2, 1, 3, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 4, 2, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 4, 3, 3, 3, 2, 3, 3, 3, 2, 1, 2, 3, 2, 2, 3, 3, 3, 3, 1, 1, 3, 2, 4, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 1, 2, 2, 3, 1, 3, 2, 4, 2, 2, 1, 1, 1, 3, 3, 3, 4, 2, 3, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 2, 4, 1, 3, 3, 1, 1, 1, 3, 3, 2, 4, 3, 3, 2, 3, 2, 3, 0, 3, 3, 2, 3, 4, 3, 2, 2, 2, 3, 1, 4, 3, 3, 2, 3, 3, 4, 1, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "pred_labels_par_int = list(map(int, pred_labels_par))\n",
    "print(pred_labels_par)\n",
    "print(pred_labels_par_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score = np.zeros(1800)\n",
    "new_score_par = np.zeros(1800)\n",
    "new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_score[test_indices] = pred_labels_int\n",
    "new_score_par[test_indices] = pred_labels_par_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 4., ..., 3., 2., 2.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_score_normalized']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(new_score, 'model_score_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_score_paraphrase_normalized']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(new_score, 'model_score_paraphrase_normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance to predict paraphrased essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7838888888888889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_score(new_score, new_score_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459892540002762"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QWK\n",
    "quadratic_weighted_kappa(new_score, new_score_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance comparison between original and gibberish-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gib = model\n",
    "model_ori = joblib.load('model_asap6_extended_780_normalized')\n",
    "data_gib = joblib.load('gibberish_200text_780')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_gib = xgboost.DMatrix(data_gib, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gib = model_gib.predict(d_data_gib)\n",
    "pred_ori = model_ori.predict(d_data_gib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gib = np.round(pred_gib)\n",
    "pred_ori = np.round(pred_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Gibberish :  Counter({-0.0: 194, 1.0: 6})\n",
      "Model Original :  Counter({1.0: 115, 0.0: 83, 2.0: 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Model Gibberish : \", Counter(pred_gib))\n",
    "print(\"Model Original : \", Counter(pred_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = xgboost.DMatrix(x, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model_ori.predict(d_data)\n",
    "pred2 = model_gib.predict(d_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.round(pred1)\n",
    "pred2 = np.round(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205878354159714"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_weighted_kappa(pred1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 780)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(1800)\n",
    "X_train, X_test, Y_train, Y_test, idx1, idx2 = train_test_split(x, y, indices, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgboost.DMatrix(X_test, feature_names=feature_names)\n",
    "pred1 = model_ori.predict(d_test)\n",
    "pred1 = np.round(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8244318181818182"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_weighted_kappa(pred1, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model_gib.predict(d_test)\n",
    "pred2 = np.round(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799757281553398"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_weighted_kappa(pred2, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 780)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(2000)\n",
    "X_train, X_test, Y_train, Y_test, idx1, idx2_gib = train_test_split(x_gib, y_gib, indices, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2_gib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_indices))\n",
    "fold1 = test_indices[0:400]\n",
    "fold2 = test_indices[400:800]\n",
    "fold3 = test_indices[800:1200]\n",
    "fold4 = test_indices[1200:1600]\n",
    "fold5 = test_indices[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "360\n",
      "361\n",
      "363\n",
      "358\n"
     ]
    }
   ],
   "source": [
    "filter1 = [a for a in fold1 if a < 1800]\n",
    "print(len(filter1))\n",
    "filter2 = [a for a in fold2 if a < 1800]\n",
    "print(len(filter2))\n",
    "filter3 = [a for a in fold3 if a < 1800]\n",
    "print(len(filter3))\n",
    "filter4 = [a for a in fold4 if a < 1800]\n",
    "print(len(filter4))\n",
    "filter5 = [a for a in fold5 if a < 1800]\n",
    "print(len(filter5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 29, 30, 32, 44, 45, 49, 56, 59, 63, 65, 67, 69, 70, 73, 76, 78, 99, 100, 109, 111, 115, 120, 123, 124, 128, 135, 162, 163, 168, 173, 175, 185, 188, 194, 196, 203, 210, 211, 212, 218, 220, 231, 233, 237, 239, 247, 251, 254, 256, 261, 266, 270, 275, 281, 289, 297, 298, 300, 303, 305, 306, 307, 316, 322, 324, 331, 342, 344, 350, 351, 352, 353, 354, 361, 366, 367, 368, 374, 382, 383, 393, 394, 411, 414, 416, 422, 427, 429, 432, 433, 438, 450, 453, 462, 464, 471, 478, 479, 480, 482, 485, 494, 495, 507, 514, 519, 526, 527, 529, 530, 534, 535, 538, 543, 544, 552, 554, 555, 570, 572, 579, 581, 582, 583, 584, 585, 591, 599, 602, 607, 610, 611, 613, 617, 618, 620, 628, 630, 637, 651, 654, 670, 674, 678, 679, 693, 701, 712, 720, 730, 743, 744, 746, 755, 757, 759, 764, 771, 780, 782, 785, 787, 788, 792, 802, 807, 808, 824, 829, 832, 834, 855, 857, 862, 874, 879, 886, 887, 888, 889, 905, 906, 907, 909, 916, 930, 937, 938, 944, 949, 964, 965, 973, 974, 978, 987, 990, 993, 1004, 1027, 1033, 1036, 1041, 1053, 1054, 1063, 1075, 1078, 1080, 1083, 1084, 1089, 1091, 1100, 1103, 1105, 1107, 1116, 1118, 1120, 1134, 1137, 1164, 1173, 1178, 1179, 1182, 1185, 1190, 1193, 1196, 1198, 1223, 1225, 1229, 1233, 1242, 1244, 1245, 1259, 1265, 1273, 1274, 1278, 1284, 1289, 1290, 1292, 1301, 1310, 1313, 1319, 1323, 1324, 1333, 1335, 1345, 1350, 1364, 1370, 1378, 1381, 1384, 1394, 1395, 1412, 1414, 1419, 1423, 1425, 1431, 1433, 1440, 1449, 1450, 1453, 1460, 1464, 1465, 1472, 1473, 1474, 1483, 1487, 1491, 1497, 1502, 1510, 1512, 1518, 1530, 1532, 1537, 1541, 1543, 1544, 1546, 1550, 1551, 1555, 1556, 1562, 1563, 1566, 1567, 1568, 1573, 1592, 1593, 1600, 1605, 1608, 1609, 1610, 1612, 1615, 1618, 1621, 1623, 1624, 1640, 1646, 1647, 1652, 1654, 1658, 1659, 1664, 1666, 1673, 1674, 1675, 1686, 1691, 1696, 1697, 1699, 1710, 1713, 1719, 1728, 1729, 1731, 1736, 1737, 1739, 1741, 1745, 1754, 1756, 1766, 1767, 1782, 1784, 1789, 1794, 1798]\n"
     ]
    }
   ],
   "source": [
    "print(filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN3HQMFChho9T220xbyEqpV",
   "collapsed_sections": [],
   "name": "GradientBoosting_Sentence-Bert_asap6_mixedEase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
