{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3b5430-0437-4ea1-aff8-2a5c59b5fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from counterfactual_inter_sbert import get_corrections_from_LLM_grammar, get_corrections_from_LLM_longer,get_prompt_grammar, get_prompt_longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79324cd-0f3d-4af9-9323-7062e39cefcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19392</td>\n",
       "      <td>My at saying your patient is. Your patient whe...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18926</td>\n",
       "      <td>Once upon a time there was a young girl named ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18318</td>\n",
       "      <td>Patience is hard. You always @CAPS1 it now not...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18904</td>\n",
       "      <td>Patience, @CAPS6 essential part of our world. ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19131</td>\n",
       "      <td>One time I was pacient was when my mum said th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                              essay  domain1_score\n",
       "0     19392  My at saying your patient is. Your patient whe...             12\n",
       "1     18926  Once upon a time there was a young girl named ...             18\n",
       "2     18318  Patience is hard. You always @CAPS1 it now not...             14\n",
       "3     18904  Patience, @CAPS6 essential part of our world. ...             14\n",
       "4     19131  One time I was pacient was when my mum said th...              8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ASAP7 Test Set.tsv', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36bf31b-4f1a-48ce-a0d8-293bc31c1ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19392</td>\n",
       "      <td>My at saying your patient is. Your patient whe...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18926</td>\n",
       "      <td>Once upon a time there was a young girl named ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18318</td>\n",
       "      <td>Patience is hard. You always @CAPS1 it now not...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18904</td>\n",
       "      <td>Patience, @CAPS6 essential part of our world. ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19131</td>\n",
       "      <td>One time I was pacient was when my mum said th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                              essay  domain1_score\n",
       "0     19392  My at saying your patient is. Your patient whe...             12\n",
       "1     18926  Once upon a time there was a young girl named ...             18\n",
       "2     18318  Patience is hard. You always @CAPS1 it now not...             14\n",
       "3     18904  Patience, @CAPS6 essential part of our world. ...             14\n",
       "4     19131  One time I was pacient was when my mum said th...              8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 100 data to get corrections from OpenAI\n",
    "data_100 = data[:100]\n",
    "data_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcb23f9c-4cfa-416a-b135-02352227f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I believe that computers are a great invention. It lets people interact with people from very far off places. Has lots of fun games you can play. And it is also a great way to learn information on topics and places very far off. Being able to talk to relatives from far away places is very important. @PERCENT1 of experts say that having a close knit family will give kids a greater chance of going to college. I understand why some people think \"well why doesn\\'t the \" I grew up in a big family and just the whole day the phone was getting used. The computer has a lot of fun games that you can play. I see why you might think that the computer is why kids are over-weight But isn\\'t the hour on the computer. Its eating habbits. Studies show that computers are use in the winter two time as much then. Going on the internet to learn new information is a great way to useing your souce. Just imagine this you straight A student comes home for the weekend about to do the biggest project lige forgets to bring home the most important book. She is flipping out looking all over the place and hyperventalating. But if you had a computer your daughter would be able to get the proect done and go to the college of her dreams. But since you didn\\'t buy a computer she is going to fail her class not accepted to harvard and settle for the local community college where maybe one day she will be able to transfer. So I\\'ve gave you reasons to go out and but a computer you just lost to go do it. Do you want your kids to interact with aunt sally who lives @NUM1 miles away. Also it is a great way to play games. And lastly you want your daughter to go to yale or do you want her to fail. I have give yous you the facts the rest is up to you.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay = data_100.iloc[77]['essay']\n",
    "essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b6d674-91e8-4b76-8a1a-185fa2149f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting grammar corrections from LLM ... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'original': 'half way',\n",
       "  'correction': 'halfway',\n",
       "  'type': 'Spelling',\n",
       "  'sentence': 6},\n",
       " {'original': 'the passport were',\n",
       "  'correction': 'the passports were',\n",
       "  'type': 'Grammatical',\n",
       "  'sentence': 8},\n",
       " {'original': 'a lot whining',\n",
       "  'correction': 'a lot of whining',\n",
       "  'type': 'Grammatical',\n",
       "  'sentence': 7},\n",
       " {'original': 'for @LOCATION3 citizens',\n",
       "  'correction': 'for the citizens of @LOCATION3',\n",
       "  'type': 'Word Choice',\n",
       "  'sentence': 4},\n",
       " {'original': 'we were coming',\n",
       "  'correction': 'we were returning',\n",
       "  'type': 'Word Choice',\n",
       "  'sentence': 2}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLINE CORRECTIONS (REQUEST TO OPENAI's LLM)\n",
    "essay = data_100.iloc[30]['essay']\n",
    "model_name = 'gpt-4o-mini'\n",
    "corrections_grammar = get_corrections_from_LLM_grammar(essay, model_name)\n",
    "corrections_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa3cff3-4670-473a-af59-0debfcd53522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 10 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 20 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 30 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 40 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 50 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 60 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 70 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 80 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 90 / 100 essays\n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Requesting grammar corrections from LLM ... \n",
      "Processed 100 / 100 essays\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the JSON responses\n",
    "json_responses = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in data_100.iterrows():\n",
    "    try:\n",
    "        # Extract the essay text\n",
    "        essay = row['essay']\n",
    "        # Get the JSON response from the function\n",
    "        json_response = get_corrections_from_LLM_grammar(essay, model_name='gpt-4o')\n",
    "        # Append the result to the list\n",
    "        json_responses.append(json_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        json_rsponses.append(None)  # Append None or an empty dict if an error occurs\n",
    "    \n",
    "    # Print progress every 10 iterations\n",
    "    if (index + 1) % 10 == 0:\n",
    "        print(f\"Processed {index + 1} / {len(data_100)} essays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cac02fb-163c-413a-b275-a25d93aac88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb4fff6-9885-4c57-88d0-e91ffaeedf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/json_responses_test_100']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(json_responses, 'files/json_responses_test_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e38dd3-47f9-4d63-be5f-6fca1c35939b",
   "metadata": {},
   "source": [
    "#### Error Corrections (eg. Corrections less than 5, which becomes a problem later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14243e8-0eb4-4d94-a43e-993fc693c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = joblib.load('files/json_responses_test_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fda8ff3-d2b5-4f08-9fcd-405ebb7815c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'original': 'half way',\n",
       "  'correction': 'halfway',\n",
       "  'type': 'Spelling',\n",
       "  'sentence': 6},\n",
       " {'original': 'a lot whining',\n",
       "  'correction': 'a lot of whining',\n",
       "  'type': 'Grammatical',\n",
       "  'sentence': 7},\n",
       " {'original': 'passport were',\n",
       "  'correction': 'passports were',\n",
       "  'type': 'Grammatical',\n",
       "  'sentence': 8}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379e3e66-df19-4e8d-a256-056dc1370c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections[30] = corrections_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9670345-9434-4833-8710-51d183200688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8695747-17c0-4572-8f50-d54f2aa4c3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/json_responses_test_100']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(corrections, 'files/json_responses_test_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb6c7c-a7d3-4de8-9162-09e74a8e08a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba9d7b19-83ff-40f0-b5d7-e48c2469d825",
   "metadata": {},
   "source": [
    "#### Check Missing Corrections (less than 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f9b322b-5acb-4106-97eb-676212c771dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inner in enumerate(corrections):\n",
    "    if not isinstance(inner, (list, tuple)):\n",
    "        print(f\"Row {i}: not a list (type={type(inner)})\")\n",
    "    elif len(inner) < 5:\n",
    "        print(f\"Row {i}: length = {len(inner)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb0241-5c91-4a37-a92b-3462bf1b2a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
