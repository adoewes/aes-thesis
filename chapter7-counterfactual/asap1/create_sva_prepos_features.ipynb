{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc19752-2747-44d1-aca6-44de70b9aab7",
   "metadata": {},
   "source": [
    "### Test using dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da32db68-2669-4ee2-a608-f6a43e5c7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from counterfactual_inter_sbert import sanitize_string, extract_json, get_essay_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032d8cf3-3c11-4a6b-afbe-0083906080e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   essay_id                                              essay  domain1_score\n",
      "0         1                       I am going above the school.              8\n",
      "1         2  I am afraid from snakes. I am waiting around you.              9\n"
     ]
    }
   ],
   "source": [
    "# Create dummy dataframe\n",
    "asap_data = pd.DataFrame({\n",
    "    'essay_id': [1, 2],\n",
    "    'essay': [\n",
    "        \"I am going above the school.\",\n",
    "        \"I am afraid from snakes. I am waiting around you.\"\n",
    "    ],\n",
    "    'domain1_score': [8, 9]  # Dummy scores\n",
    "})\n",
    "\n",
    "print(asap_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a2bc8-7206-48a0-91ac-2982e78cb1a9",
   "metadata": {},
   "source": [
    "### Get the number of preposition errors per essay in ASAP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "195c95de-f70d-4371-ae11-800f661e8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepositional_error import get_prepositional_errors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf79224-8989-47e5-b601-211e06d08108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                              essay  domain1_score\n",
       "0         1  Dear local newspaper, I think effects computer...              8\n",
       "1         2  Dear @CAPS1 @CAPS2, I believe that using compu...              9\n",
       "2         3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...              7\n",
       "3         4  Dear Local Newspaper, @CAPS1 I have found that...             10\n",
       "4         5  Dear @LOCATION1, I know having computers has a...              8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
    "PROMPT = 1\n",
    "asap = df[df['essay_set'] == PROMPT]\n",
    "asap = asap[['essay_id', 'essay', 'domain1_score']]\n",
    "asap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ed9ee8-ab5d-4e06-908e-28336422aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/1783 essays...\n",
      "Processed 20/1783 essays...\n",
      "Processed 30/1783 essays...\n",
      "Processed 40/1783 essays...\n",
      "Processed 50/1783 essays...\n",
      "Processed 60/1783 essays...\n",
      "Processed 70/1783 essays...\n",
      "Processed 80/1783 essays...\n",
      "Processed 90/1783 essays...\n",
      "Processed 100/1783 essays...\n",
      "Processed 110/1783 essays...\n",
      "Processed 120/1783 essays...\n",
      "Processed 130/1783 essays...\n",
      "Processed 140/1783 essays...\n",
      "Processed 150/1783 essays...\n",
      "Processed 160/1783 essays...\n",
      "Processed 170/1783 essays...\n",
      "Processed 180/1783 essays...\n",
      "Processed 190/1783 essays...\n",
      "Processed 200/1783 essays...\n",
      "Processed 210/1783 essays...\n",
      "Processed 220/1783 essays...\n",
      "Processed 230/1783 essays...\n",
      "Processed 240/1783 essays...\n",
      "Processed 250/1783 essays...\n",
      "Processed 260/1783 essays...\n",
      "Processed 270/1783 essays...\n",
      "Processed 280/1783 essays...\n",
      "Processed 290/1783 essays...\n",
      "Processed 300/1783 essays...\n",
      "Processed 310/1783 essays...\n",
      "Processed 320/1783 essays...\n",
      "Processed 330/1783 essays...\n",
      "Processed 340/1783 essays...\n",
      "Processed 350/1783 essays...\n",
      "Processed 360/1783 essays...\n",
      "Processed 370/1783 essays...\n",
      "Processed 380/1783 essays...\n",
      "Processed 390/1783 essays...\n",
      "Processed 400/1783 essays...\n",
      "Processed 410/1783 essays...\n",
      "Processed 420/1783 essays...\n",
      "Processed 430/1783 essays...\n",
      "Processed 440/1783 essays...\n",
      "Processed 450/1783 essays...\n",
      "Processed 460/1783 essays...\n",
      "Processed 470/1783 essays...\n",
      "Processed 480/1783 essays...\n",
      "Processed 490/1783 essays...\n",
      "Processed 500/1783 essays...\n",
      "Processed 510/1783 essays...\n",
      "Processed 520/1783 essays...\n",
      "Processed 530/1783 essays...\n",
      "Processed 540/1783 essays...\n",
      "Processed 550/1783 essays...\n",
      "Processed 560/1783 essays...\n",
      "Processed 570/1783 essays...\n",
      "Processed 580/1783 essays...\n",
      "Processed 590/1783 essays...\n",
      "Processed 600/1783 essays...\n",
      "Processed 610/1783 essays...\n",
      "Processed 620/1783 essays...\n",
      "Processed 630/1783 essays...\n",
      "Processed 640/1783 essays...\n",
      "Processed 650/1783 essays...\n",
      "Processed 660/1783 essays...\n",
      "Processed 670/1783 essays...\n",
      "Processed 680/1783 essays...\n",
      "Processed 690/1783 essays...\n",
      "Processed 700/1783 essays...\n",
      "Processed 710/1783 essays...\n",
      "Processed 720/1783 essays...\n",
      "Processed 730/1783 essays...\n",
      "Processed 740/1783 essays...\n",
      "Processed 750/1783 essays...\n",
      "Processed 760/1783 essays...\n",
      "Processed 770/1783 essays...\n",
      "Processed 780/1783 essays...\n",
      "Processed 790/1783 essays...\n",
      "Processed 800/1783 essays...\n",
      "Processed 810/1783 essays...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#sample_data = asap.head(3).copy()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m processed_sample \u001b[38;5;241m=\u001b[39m \u001b[43mget_prepositional_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43masap\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python Scripts\\counterfactual_chapter7\\asap1_new\\prepositional_error.py:130\u001b[0m, in \u001b[0;36mget_prepositional_errors\u001b[1;34m(df, essay_col)\u001b[0m\n\u001b[0;32m    126\u001b[0m prompt \u001b[38;5;241m=\u001b[39m get_prompt() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(sentences)\n\u001b[0;32m    128\u001b[0m corrections \u001b[38;5;241m=\u001b[39m openai_request(prompt)\n\u001b[1;32m--> 130\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mextract_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreposition_corrections\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    134\u001b[0m prep_error_counts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[1;32mD:\\Python Scripts\\counterfactual_chapter7\\asap1_new\\prepositional_error.py:31\u001b[0m, in \u001b[0;36mextract_json\u001b[1;34m(data_str)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# If we can't find a JSON start or end, return an error or None\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json_start \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m json_end \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo JSON object could be decoded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Extract the substring that is likely to be JSON\u001b[39;00m\n\u001b[0;32m     34\u001b[0m potential_json_str \u001b[38;5;241m=\u001b[39m data_str[json_start:json_end \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "#sample_data = asap.head(3).copy()\n",
    "processed_sample = get_prepositional_errors(asap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a58daf-ed58-4914-b169-ea391b1e57fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e639feb-309e-402c-81cb-9d12090963b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a097fa03-3254-40a8-bb4d-21e6221d9088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "a = joblib.load('preposition_corrections')\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "577a0451-9f6d-4e5b-888e-edfd967c2fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'original': 'for', 'correction': 'to', 'type': 'Preposition', 'sentence': 5},\n",
       " {'original': 'of', 'correction': 'in', 'type': 'Preposition', 'sentence': 19}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58fce1d9-6d05-4313-8218-cc8c82a97d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prep_error_count</th>\n",
       "      <th>prep_error_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'original': 'about', 'correction': 'with', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'original': 'with', 'correction': 'to', 'typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'original': 'in', 'correction': 'of', 'type'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id                                              essay  domain1_score  \\\n",
       "0         1  Dear local newspaper, I think effects computer...              8   \n",
       "1         2  Dear @CAPS1 @CAPS2, I believe that using compu...              9   \n",
       "2         3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...              7   \n",
       "\n",
       "   prep_error_count                                    prep_error_list  \n",
       "0                 8  [{'original': 'about', 'correction': 'with', '...  \n",
       "1                 8  [{'original': 'with', 'correction': 'to', 'typ...  \n",
       "2                 5  [{'original': 'in', 'correction': 'of', 'type'...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2430af1a-30c4-4eeb-a820-4cd067c8d864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Essay 1:\n",
      "[\n",
      "  {\n",
      "    \"original\": \"about\",\n",
      "    \"correction\": \"with\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 5\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"to\",\n",
      "    \"correction\": \"on\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 6\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"about\",\n",
      "    \"correction\": \"with\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 10\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"than\",\n",
      "    \"correction\": \"as\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 11\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"in\",\n",
      "    \"correction\": \"at\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 12\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"than\",\n",
      "    \"correction\": \"for\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 12\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"on\",\n",
      "    \"correction\": \"for\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 14\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"on\",\n",
      "    \"correction\": \"to\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 15\n",
      "  }\n",
      "]\n",
      "\n",
      "Essay 2:\n",
      "[\n",
      "  {\n",
      "    \"original\": \"with\",\n",
      "    \"correction\": \"to\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 3\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"in\",\n",
      "    \"correction\": \"on\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 5\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"by\",\n",
      "    \"correction\": \"to\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 6\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"for\",\n",
      "    \"correction\": \"about\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 8\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"of\",\n",
      "    \"correction\": \"on\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 13\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"on\",\n",
      "    \"correction\": \"in\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 15\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"for\",\n",
      "    \"correction\": \"to\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 16\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"in\",\n",
      "    \"correction\": \"on\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 20\n",
      "  }\n",
      "]\n",
      "\n",
      "Essay 3:\n",
      "[\n",
      "  {\n",
      "    \"original\": \"in\",\n",
      "    \"correction\": \"of\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 4\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"on\",\n",
      "    \"correction\": \"in\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 8\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"to\",\n",
      "    \"correction\": \"of\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 9\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"of\",\n",
      "    \"correction\": \"for\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 10\n",
      "  },\n",
      "  {\n",
      "    \"original\": \"of\",\n",
      "    \"correction\": \"off\",\n",
      "    \"type\": \"Preposition\",\n",
      "    \"sentence\": 12\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for i, row in processed_sample.iterrows():\n",
    "    print(f\"\\nEssay {i+1}:\")\n",
    "    if row[\"prep_error_list\"]:\n",
    "        print(json.dumps(row[\"prep_error_list\"], indent=2))\n",
    "    else:\n",
    "        print(\"âœ… No prepositional errors found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cad9f6a-16bf-41f9-ac14-592f81ccee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_data.iloc[0]['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66b6cf3-685d-42dd-a6f3-9755986a5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import sent_tokenize\n",
    "# sents = sent_tokenize(sample_data.iloc[0]['essay'])\n",
    "\n",
    "# # Print each sentence with its sentence number\n",
    "# for i, sent in enumerate(sents, start=1):\n",
    "#     print(f\"{i}: {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c4502c1-3f05-4d90-9dcc-de2571aa227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'processed_sample' is your DataFrame and it has a column 'prep_error_list'\n",
    "prep_error_counts = processed_sample['prep_error_list'].apply(len).to_numpy()\n",
    "\n",
    "print(prep_error_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce2281-e80f-4c9b-a9af-1193b3076c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd4705-8b9d-4865-aeef-375bc0b9f31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
