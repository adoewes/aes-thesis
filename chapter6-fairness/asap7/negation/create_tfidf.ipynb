{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e36a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f32b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\20167947\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('training_set_7_final.txt', sep='\\t', error_bad_lines=False, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4f30ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patience is when your waiting .I was patience ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am not a patience person, like I cant sit i...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One day I was at basketball practice and I was...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I going to write about a time when I went to t...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It can be very hard for somebody to be patient...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>One time I was getting a cool @CAPS1 game it w...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>A patent person in my life is my mom. Aicason ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>A time when someone else I know was patient wa...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>I hate weddings. I love when people get marrie...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>A few weeks ago, we had a garage sale and a mo...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay  domain1_score\n",
       "0     Patience is when your waiting .I was patience ...             15\n",
       "1     I am not a patience person, like I cant sit i...             13\n",
       "2     One day I was at basketball practice and I was...             15\n",
       "3     I going to write about a time when I went to t...             17\n",
       "4     It can be very hard for somebody to be patient...             13\n",
       "...                                                 ...            ...\n",
       "1564  One time I was getting a cool @CAPS1 game it w...             12\n",
       "1565  A patent person in my life is my mom. Aicason ...             16\n",
       "1566  A time when someone else I know was patient wa...             19\n",
       "1567  I hate weddings. I love when people get marrie...             22\n",
       "1568  A few weeks ago, we had a garage sale and a mo...             15\n",
       "\n",
       "[1569 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b444bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.read_csv('essay_samples.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3982401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_cleantext_tokenizer(text, remove_nonletters = False, remove_stopwords=False, stemming=False, lemma=False):\n",
    "\n",
    "    # 1. Remove HTML\n",
    "    teks = BeautifulSoup(text, 'lxml').get_text()\n",
    "\n",
    "    # 2. Remove non-ASCII\n",
    "    letters_only = re.sub(r\"[^\\x00-\\x7F]+\", \" \", teks)\n",
    "\n",
    "    if remove_nonletters:\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", letters_only)\n",
    "\n",
    "    #letters_only = teks\n",
    "\n",
    "    # 3. Convert to lower-case, split into words\n",
    "    words = letters_only.lower()\n",
    "    words = word_tokenize(words)\n",
    "\n",
    "    # 4. Convert stopwords into Set (faster than List)\n",
    "    # 5. Remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    # 6. Stemming\n",
    "    if stemming:\n",
    "        porter = PorterStemmer()\n",
    "        stems = []\n",
    "        for t in words:\n",
    "            stems.append(porter.stem(t))\n",
    "        words = stems\n",
    "\n",
    "    # 7. Stemming\n",
    "    if lemma:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmas = []\n",
    "        for t in words:\n",
    "            lemmas.append(lemmatizer.lemmatize(t))\n",
    "        words = lemmas\n",
    "        \n",
    "    # 8. Join words back into one string by space, and return the result\n",
    "    return(\" \".join(words))\n",
    "    # 8. Return list of words\n",
    "    # return(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0cfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_essays = df['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c57ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_essays = df_neg['new_meaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820afaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Patience is when your waiting .I was patience ...\n",
       "1       I am not a patience person, like I cant sit i...\n",
       "2       One day I was at basketball practice and I was...\n",
       "3       I going to write about a time when I went to t...\n",
       "4       It can be very hard for somebody to be patient...\n",
       "                              ...                        \n",
       "1614    We climbed in the rental car saying hello to r...\n",
       "1615    A short wait   @CAPS1 'only four' at the time....\n",
       "1616    I had another math home work assignment due to...\n",
       "1617    Once upon a time thime was a boy named @PERSON...\n",
       "1618    This is a story about when I was impatient. My...\n",
       "Length: 1619, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_essays = pd.concat([original_essays, negation_essays], ignore_index=True)\n",
    "all_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee52c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patience is when your waiting .I was patience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am not a patience person, like I cant sit i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One day I was at basketball practice and I was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I going to write about a time when I went to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It can be very hard for somebody to be patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>We climbed in the rental car saying hello to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>A short wait   @CAPS1 'only four' at the time....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>I had another math home work assignment due to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>Once upon a time thime was a boy named @PERSON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>This is a story about when I was impatient. My...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1619 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay\n",
       "0     Patience is when your waiting .I was patience ...\n",
       "1     I am not a patience person, like I cant sit i...\n",
       "2     One day I was at basketball practice and I was...\n",
       "3     I going to write about a time when I went to t...\n",
       "4     It can be very hard for somebody to be patient...\n",
       "...                                                 ...\n",
       "1614  We climbed in the rental car saying hello to r...\n",
       "1615  A short wait   @CAPS1 'only four' at the time....\n",
       "1616  I had another math home work assignment due to...\n",
       "1617  Once upon a time thime was a boy named @PERSON...\n",
       "1618  This is a story about when I was impatient. My...\n",
       "\n",
       "[1619 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_essays, columns=['essay'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958ab872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patience is when your waiting .I was patience when in line waiting for lunch .I didn\\x92t c ut any one to eat .I was standing and waiting for my turn .Patience ,some people don\\x92t have it .Lots of people just cut or yell at you because they don\\x92t have  any patience. Sometimes people will push you out of their way .They only do that because they don\\x92t have patience at all. Patience is what people need .People need patience because lots o f feelings get hurt .Everyone should have patience.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594421df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():  \n",
    "    line = df.at[idx, 'essay']\n",
    "    line = line.encode('ascii','ignore')\n",
    "    line = text_to_cleantext_tokenizer(line, remove_nonletters=True, remove_stopwords=False, lemma=True)\n",
    "    df.at[idx,'essay'] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9154d8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patience is when your waiting i wa patience when in line waiting for lunch i didnt c ut any one to eat i wa standing and waiting for my turn patience some people dont have it lot of people just cut or yell at you because they dont have any patience sometimes people will push you out of their way they only do that because they dont have patience at all patience is what people need people need patience because lot o f feeling get hurt everyone should have patience'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4018db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1bc8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee48e9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'ability to', 'able', ..., 'zoo', 'zoom', 'zoomed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8f1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1614a524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1619"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63dee0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = feats[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c927a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = feats[:1569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43a3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_neg['index'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "727691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = ori[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215bc996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c51c49ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 582,  466, 1138,  178,   46, 1311,  353,  402,  675,  507,  973,\n",
       "        267, 1263,  747, 1250, 1315,  205, 1356,   51,    0,  277,  660,\n",
       "        412,  808, 1087, 1357,  171,  722, 1211, 1014,  903,  505,  259,\n",
       "        355, 1312,  866,  291, 1195, 1177, 1106,  478, 1076,  386,  673,\n",
       "       1241,  614, 1021, 1182, 1079,  131], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca721119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0e52791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac7e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f3e1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg_tfidf']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ori, 'ori_tfidf')\n",
    "joblib.dump(neg, 'neg_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "690b2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['essay_ngram_no_stopword_asap7']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(X.toarray(), 'essay_ngram_no_stopword_asap7')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
